{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prévision de la hausse ou de la baisse du prix de l'électricité : régression logistique  polynomiale \n",
    "Le jeu de données étudié comporte  4 années de consommation électrique, de prix et de production pour l'Espagne. Les données de consommation et de production ont été extraites de l'ENTSOE, un \n",
    "portail public pour les données des opérateurs de services de transmission. Les prix de l'électricité ont été obtenus auprès du GRT espagnol Red Electric España.\n",
    "[Source](https://transparency.entsoe.eu/dashboard/show)\n",
    "\n",
    "Prédire les écarts importants entre le prix actuel et  le prix day ahead.  \n",
    "Pour cela, vous allez \n",
    "- implémenter la régression logistique polynomiale et tester différents ordres pour le polynôme.\n",
    "- vérifier les performances des modèles en utilisant les métriques appropriées à la classification.\n",
    "- détecter l'overfitting  \n",
    "- tester au moins un type de régularisation (L1, L2, Elastic-Net) pour contrer l'overfitting et vérifier l'amélioration des performances avec régularisation.\n",
    "\n",
    "Ce notebook vous aide à commencer en définissant les features et outputs /classes.\n",
    "\n",
    "Les contraintes sont l'utilisation du module scikit learn, même si vous verrez d'autres outils plus tard. \n",
    "\n",
    "Pour vous aider dans l'implémentation, vous trouverez les modules nécessaires sur cette page web :  \n",
    "https://scikit-learn.org/stable/api/sklearn.linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ref1'> Importation des modules </a>  \n",
    "\n",
    "A compléter avec les modèles et méthodes adaptées à la classification avec régression logistique\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "#importation des librairies de manipulation de données et de visualisation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme(style = \"darkgrid\", palette = \"husl\")\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# importation des librairies de machine learning\n",
    "\n",
    "# prétraitement\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# modèles \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# calcul de performance\n",
    "from sklearn.model_selection import LearningCurveDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation des librairies de machine learning pour la classification\n",
    "# à compléter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ref1'>1. Charger les données  d'apprentissage et de test</a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the energy data from the CSV file\n",
    "df_energy = pd.read_csv('data/ISC_Spain_Energy.csv')\n",
    "\n",
    "# Define the features and target variable\n",
    "features = [\"generation biomass (MW)\", \"generation fossil brown coal/lignite (MW)\", \"generation fossil gas (MW)\",\n",
    "            \"generation fossil hard coal (MW)\", \"generation fossil oil (MW)\", \"total load actual (MW)\",\n",
    "            \"price day ahead (EUR/MWh)\", \"price for the previous hour (EUR/MWh)\",\"total production (MW)\"]\n",
    "X_train = df_energy[features]\n",
    "y_train = (df_energy[\"price actual (EUR/MWh)\"] - df_energy[\"price day ahead (EUR/MWh)\"]).abs()>8\n",
    "\n",
    "# test data\n",
    "newdf_energy = pd.read_csv('data/ISC_Spain_Energy_NewData.csv')\n",
    "X_test = newdf_energy[features]\n",
    "\n",
    "y_test = pd.read_csv('data/ISC_Spain_Energy_NewDataSolution.csv')\n",
    "y_test = (y_test[\"price actual (EUR/MWh)\"] - newdf_energy[\"price day ahead (EUR/MWh)\"]).abs()>8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez ( et devez) vérifier ce que contient la variable `y_train` et `y_test`. En particulier si le ratio de 0 et de 1 sont à peu près les mêmes pour les deux jeux de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate value counts and ratios for y_train\n",
    "train_counts = y_train.value_counts()\n",
    "train_ratios = train_counts / len(y_train)\n",
    "\n",
    "# Calculate value counts and ratios for y_test\n",
    "test_counts = y_test.value_counts()\n",
    "test_ratios = test_counts / len(y_test)\n",
    "\n",
    "# Create a barplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(train_ratios.index, train_ratios, label='y_train', alpha=0.7,width=0.2)  # Plot the bars for y_train\n",
    "plt.bar(test_ratios.index + 0.2, test_ratios, label='y_test', alpha=0.7,width=0.2)  # Shift the bars for y_test\n",
    "plt.xlabel('Class')\n",
    "plt.xticks(train_ratios.index+0.1, [\"Petits écarts\", \"Grands écarts\"])\n",
    "plt.ylabel('Ratio')\n",
    "plt.title('Ratio of Value Counts for y_train and y_test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est aussi utile d'afficher la valeur de, par exemple, le prix day ahead et les prix réels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Create a boxplot\n",
    "sns.boxplot(data=df_energy, x='Hausse', y='price for the previous hour (EUR/MWh)')\n",
    "\n",
    "# Set the labels and title\n",
    "plt.xlabel('Hausse')\n",
    "plt.ylabel('Price for the previous hour (EUR/MWh)')\n",
    "plt.title('Boxplot of Price for the Previous Hour')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connaître le prix de l'heure précédente n'aide pas beaucoup pour prédire si il y a baisse ou hausse.  \n",
    "Essayons tout de même en utilisant les mêmes features que pour les notebooks sur la régression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ref2'>2. Implémentation d'un modèle de régression logistique polynomiale et choix de l'ordre du polynome</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette partie, vous devez créer un modèle linéaire sans régularisation qui va prédire lorsque le prix réel (inconnu) s'écarte trop du prix day ahead à partir de `features`.   \n",
    "La procédure d'apprentissage consiste à estimer les paramètres de ce modèle de régression logistique linéaire.  \n",
    "- **Trouver la méthode sous scikitlearn et implémentez là.**\n",
    "- **Estimer les paramètres du modèle et calculer l'erreur sur les données en utilisant la métrique `accuracy_score` vue en cours.**   Elle va de 0 à 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Ajouter ensuite des calculs de termes polynomiaux et augmenter l'ordre des polynômes jusqu'à détecter l'overfitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ref3'>3. Réduire l'overfitting avec régularisation </a>\n",
    "Nous voudrions savoir si le modèle qui fait de l'overfitting pourrait avec de l'aide améliorer ses performances sur les données test.  \n",
    "C'est le moment de tester les deux méthodes de régularisation vues en cours :\n",
    "- la L2 (norme 2), aussi appelée Ridge Regression  ou régularisation de Tikhonov : \n",
    "- la L1 (norme L1) aussi appelée Lasso Regression : sous scikit learn  Logistic Regression \n",
    "\n",
    "\n",
    "La régularisation modifie la fonction coût /objectif à minimiser en ajoutant un terme supplémentaire. Il faut donc choisir le poids, l'importance de ce terme.   \n",
    "Trouver la méthode sous scikit learn qui permet de choisir le type de régularisation et le paramètre qui permet de régler l'importance de ce terme.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='ref4'>4. Wrap-up et conclusion </a>\n",
    "Faites un graphique permettant de montrer pourquoi le modèle et la fonction coût choisi sont les meilleurs.  \n",
    "Argumentez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
